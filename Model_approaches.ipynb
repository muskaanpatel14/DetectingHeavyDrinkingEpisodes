{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import scipy \n",
    "np.random.seed(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset With Raw X, Y, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BK7610', 'BU4707', 'DC6359', 'JB3156', 'JR8022', 'MC7070',\n",
       "       'SF3079'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Sliding window False\n",
    "Raw X, Y, Z data \n",
    "Sampling Rate = 20 \n",
    "\n",
    "Using 1 PID for training and 1 PID for testing\n",
    "'''\n",
    "\n",
    "with open(\"../data/pickles/all_pids_data_slidingwindowFalse10_samplingrate20_df.p\", 'rb') as f:\n",
    "  data = pk.load(f)\n",
    "dataframe = data['data']\n",
    "dataframe['pid'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1679320, 6), (614460, 6))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataframe = dataframe[(dataframe['pid'] == 'SF3079') |\n",
    "                            (dataframe['pid'] == 'BU4707') |\n",
    "                            (dataframe['pid'] == 'DC6359') |\n",
    "                            (dataframe['pid'] == 'JB3156') |\n",
    "                            (dataframe['pid'] == 'JR8022') |\n",
    "                            (dataframe['pid'] == 'MC7070') ]\n",
    "test_dataframe = dataframe[(dataframe['pid'] == 'BK7610')]\n",
    "train_dataframe.shape, test_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1679320, 6), (614460, 6))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataframe.shape, test_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7y/kyw1v_8j0g1ckfb3g6x93q1m0000gn/T/ipykernel_43436/2896753078.py:11: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  ys.append(scipy.stats.mode(labels)[0][0])\n",
      "/var/folders/7y/kyw1v_8j0g1ckfb3g6x93q1m0000gn/T/ipykernel_43436/2896753078.py:11: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  ys.append(scipy.stats.mode(labels)[0][0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((83965, 20, 3), (30722, 20, 3), (83965, 1), (30722, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Downsampling - basically we now take only one record per second instead of 20  \n",
    "'''\n",
    "\n",
    "def create_dataset(X, y, time_steps=1, step=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(0, len(X) - time_steps, step):\n",
    "        output = X.iloc[i:(i + time_steps)].values\n",
    "        labels = y.iloc[i: i + time_steps]\n",
    "        Xs.append(output)\n",
    "        ys.append(scipy.stats.mode(labels)[0][0])\n",
    "    return np.array(Xs), np.array(ys).reshape(-1, 1)\n",
    "\n",
    "\n",
    "X_train, y_train = create_dataset(train_dataframe[['x', 'y', 'z']],train_dataframe.tac,20,20)\n",
    "X_test, y_test = create_dataset(test_dataframe[['x', 'y', 'z']],test_dataframe.tac,20,20)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM on Vanilla Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 256)               266240    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 299,265\n",
      "Trainable params: 299,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.LSTM(units=256,input_shape=[X_train.shape[1], X_train.shape[2]]))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "model.add(keras.layers.Dense(y_train.shape[1], activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 16:16:41.309603: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2624/2624 [==============================] - 47s 17ms/step - loss: 0.2540 - acc: 0.9407\n",
      "Epoch 2/10\n",
      "2624/2624 [==============================] - 47s 18ms/step - loss: 0.2732 - acc: 0.8981\n",
      "Epoch 3/10\n",
      "2624/2624 [==============================] - 46s 17ms/step - loss: 0.2713 - acc: 0.8985\n",
      "Epoch 4/10\n",
      "2624/2624 [==============================] - 46s 17ms/step - loss: 0.2849 - acc: 0.9070\n",
      "Epoch 5/10\n",
      "2624/2624 [==============================] - 43s 16ms/step - loss: 0.2814 - acc: 0.8932\n",
      "Epoch 6/10\n",
      "2624/2624 [==============================] - 44s 17ms/step - loss: 0.3170 - acc: 0.8797\n",
      "Epoch 7/10\n",
      "2624/2624 [==============================] - 46s 17ms/step - loss: 0.2798 - acc: 0.8896\n",
      "Epoch 8/10\n",
      "2624/2624 [==============================] - 43s 17ms/step - loss: 0.2116 - acc: 0.9337\n",
      "Epoch 9/10\n",
      "2624/2624 [==============================] - 43s 17ms/step - loss: 0.2393 - acc: 0.9110\n",
      "Epoch 10/10\n",
      "2624/2624 [==============================] - 43s 17ms/step - loss: 0.2766 - acc: 0.9048\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=32, \n",
    "    validation_split=0.0, \n",
    "    shuffle=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "961/961 [==============================] - 6s 6ms/step - loss: 3.0656 - acc: 0.6347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.065591812133789, 0.6346917748451233]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Classifier on Vanilla Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarah_prakriti_peters/miniconda3/envs/DL/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.6060803333116334\n",
      "Prec  0.6285763949243873\n",
      "Recall  0.927278321965229\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "clf = MLPClassifier(solver='adam', shuffle=True, random_state=1)\n",
    "\n",
    "# X0_dash = np.reshape(X0, (X0.shape[0], X0.shape[1] * X0.shape[2]))\n",
    "\n",
    "clf.fit(np.reshape(X_train, (83965, 60)), y_train)\n",
    "# clf.get_params()\n",
    "\n",
    "print('Accuracy ', accuracy_score(y_test, clf.predict(np.reshape(X_test, ((30722, 60))))))\n",
    "print('Prec ', precision_score(y_test, clf.predict(np.reshape(X_test, ((30722, 60))))))\n",
    "print('Recall ', recall_score(y_test, clf.predict(np.reshape(X_test, ((30722, 60))))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM on vanilla Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (83965, 512)             532480    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (83965, 512)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (83965, 128)              65664     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (83965, 1)                129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 598,273\n",
      "Trainable params: 598,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Bidirectional(keras.layers.LSTM(units=256,input_shape=[X_train.shape[1], X_train.shape[2]])))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "model.add(keras.layers.Dense(y_train.shape[1], activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer=keras.optimizers.Adam(0.001),metrics=['acc']) \n",
    "model.build((X_train.shape)) \n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2598/2598 [==============================] - 83s 31ms/step - loss: 0.3587 - acc: 0.9193 - val_loss: 0.0917 - val_acc: 0.9881\n",
      "Epoch 2/25\n",
      "2598/2598 [==============================] - 73s 28ms/step - loss: 0.3116 - acc: 0.8936 - val_loss: 0.1700 - val_acc: 0.9881\n",
      "Epoch 3/25\n",
      "2598/2598 [==============================] - 64s 25ms/step - loss: 0.2863 - acc: 0.9133 - val_loss: 0.0824 - val_acc: 0.9881\n",
      "Epoch 4/25\n",
      "2598/2598 [==============================] - 60s 23ms/step - loss: 0.3281 - acc: 0.8943 - val_loss: 0.1634 - val_acc: 0.9881\n",
      "Epoch 5/25\n",
      "2598/2598 [==============================] - 60s 23ms/step - loss: 0.3463 - acc: 0.8890 - val_loss: 0.1259 - val_acc: 0.9881\n",
      "Epoch 6/25\n",
      "2598/2598 [==============================] - 60s 23ms/step - loss: 0.2926 - acc: 0.9241 - val_loss: 0.1166 - val_acc: 0.9881\n",
      "Epoch 7/25\n",
      "2598/2598 [==============================] - 59s 23ms/step - loss: 0.3533 - acc: 0.8574 - val_loss: 0.1069 - val_acc: 0.9881\n",
      "Epoch 8/25\n",
      "2598/2598 [==============================] - 55s 21ms/step - loss: 0.3337 - acc: 0.8690 - val_loss: 0.1148 - val_acc: 0.9881\n",
      "Epoch 9/25\n",
      "2598/2598 [==============================] - 54s 21ms/step - loss: 0.3905 - acc: 0.8708 - val_loss: 0.1177 - val_acc: 0.9881\n",
      "Epoch 10/25\n",
      "2598/2598 [==============================] - 54s 21ms/step - loss: 0.3359 - acc: 0.9163 - val_loss: 0.1224 - val_acc: 0.9881\n",
      "Epoch 11/25\n",
      "2598/2598 [==============================] - 54s 21ms/step - loss: 0.3287 - acc: 0.8847 - val_loss: 0.1006 - val_acc: 0.9881\n",
      "Epoch 12/25\n",
      "2598/2598 [==============================] - 54s 21ms/step - loss: 0.3621 - acc: 0.8655 - val_loss: 0.1402 - val_acc: 0.9881\n",
      "Epoch 13/25\n",
      "2598/2598 [==============================] - 56s 21ms/step - loss: 0.3091 - acc: 0.8891 - val_loss: 0.1195 - val_acc: 0.9881\n",
      "Epoch 14/25\n",
      "2598/2598 [==============================] - 54s 21ms/step - loss: 0.2867 - acc: 0.9087 - val_loss: 0.0819 - val_acc: 0.9881\n",
      "Epoch 15/25\n",
      "2598/2598 [==============================] - 55s 21ms/step - loss: 0.2924 - acc: 0.8851 - val_loss: 0.0958 - val_acc: 0.9881\n",
      "Epoch 16/25\n",
      "2598/2598 [==============================] - 55s 21ms/step - loss: 0.3212 - acc: 0.9229 - val_loss: 0.1376 - val_acc: 0.9881\n",
      "Epoch 17/25\n",
      "2598/2598 [==============================] - 54s 21ms/step - loss: 0.3359 - acc: 0.9161 - val_loss: 0.1596 - val_acc: 0.9881\n",
      "Epoch 18/25\n",
      "2598/2598 [==============================] - 54s 21ms/step - loss: 0.3792 - acc: 0.8669 - val_loss: 0.1102 - val_acc: 0.9881\n",
      "Epoch 19/25\n",
      "2598/2598 [==============================] - 54s 21ms/step - loss: 0.4108 - acc: 0.8613 - val_loss: 0.0831 - val_acc: 0.9881\n",
      "Epoch 20/25\n",
      "2598/2598 [==============================] - 54s 21ms/step - loss: 0.4275 - acc: 0.8283 - val_loss: 0.1006 - val_acc: 0.9881\n",
      "Epoch 21/25\n",
      "2598/2598 [==============================] - 171s 66ms/step - loss: 0.4006 - acc: 0.8777 - val_loss: 0.1671 - val_acc: 0.9881\n",
      "Epoch 22/25\n",
      "2598/2598 [==============================] - 1080s 416ms/step - loss: 0.3107 - acc: 0.9005 - val_loss: 0.0885 - val_acc: 0.9881\n",
      "Epoch 23/25\n",
      "2598/2598 [==============================] - 230s 88ms/step - loss: 0.3826 - acc: 0.8691 - val_loss: 0.0925 - val_acc: 0.9881\n",
      "Epoch 24/25\n",
      "2598/2598 [==============================] - 3081s 1s/step - loss: 0.3046 - acc: 0.8927 - val_loss: 0.1167 - val_acc: 0.9881\n",
      "Epoch 25/25\n",
      "2598/2598 [==============================] - 2764s 1s/step - loss: 0.3004 - acc: 0.9113 - val_loss: 0.0977 - val_acc: 0.9881\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=25,\n",
    "    batch_size=32, \n",
    "    validation_split=0.01, \n",
    "    shuffle=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 3s 8ms/step - loss: 0.7217 - acc: 0.7155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7217283844947815, 0.7154703736305237]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN On Vanilla Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 20\n",
    "\n",
    "flatten = keras.layers.Flatten()\n",
    "conv_layer1 = keras.layers.Conv1D(filters = 64, kernel_size = 3, padding='SAME')\n",
    "conv_layer2 = keras.layers.Conv1D(filters = 64, kernel_size = 3, padding='SAME')\n",
    "dropout = keras.layers.Dropout(0.5)\n",
    "max_pooling = keras.layers.MaxPool1D(pool_size=2)\n",
    "fc_layer = keras.layers.Dense(units=128, activation = 'relu')\n",
    "fc_layer2 = keras.layers.Dense(y_train.shape[1], activation = 'sigmoid')\n",
    "base_model = keras.Sequential([\n",
    "                                  conv_layer1,  \n",
    "                                  conv_layer2, \n",
    "                                  dropout, \n",
    "                                  max_pooling, \n",
    "                                  flatten, \n",
    "                                  fc_layer, \n",
    "                                  fc_layer2\n",
    "                                ])\n",
    "\n",
    "base_model.compile(loss='binary_crossentropy', \n",
    "                   optimizer='adam',\n",
    "                   metrics=['acc']) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "481/481 [==============================] - 3s 3ms/step - loss: 0.3220 - acc: 0.9108 - val_loss: 0.4842 - val_acc: 1.0000\n",
      "Epoch 2/20\n",
      "481/481 [==============================] - 2s 3ms/step - loss: 0.3256 - acc: 0.8806 - val_loss: 0.7588 - val_acc: 0.1795\n",
      "Epoch 3/20\n",
      "481/481 [==============================] - 2s 3ms/step - loss: 0.2737 - acc: 0.9347 - val_loss: 0.7710 - val_acc: 0.0577\n",
      "Epoch 4/20\n",
      "481/481 [==============================] - 1s 3ms/step - loss: 0.3076 - acc: 0.8955 - val_loss: 0.6665 - val_acc: 0.6731\n",
      "Epoch 5/20\n",
      "481/481 [==============================] - 2s 3ms/step - loss: 0.2746 - acc: 0.9172 - val_loss: 0.6739 - val_acc: 0.8910\n",
      "Epoch 6/20\n",
      "481/481 [==============================] - 1s 3ms/step - loss: 0.2521 - acc: 0.9015 - val_loss: 0.8488 - val_acc: 0.1538\n",
      "Epoch 7/20\n",
      "481/481 [==============================] - 1s 3ms/step - loss: 0.2694 - acc: 0.9166 - val_loss: 0.6809 - val_acc: 0.7308\n",
      "Epoch 8/20\n",
      "481/481 [==============================] - 1s 3ms/step - loss: 0.3069 - acc: 0.9009 - val_loss: 0.5666 - val_acc: 0.9744\n",
      "Epoch 9/20\n",
      "481/481 [==============================] - 1s 3ms/step - loss: 0.3028 - acc: 0.8926 - val_loss: 0.5814 - val_acc: 0.9551\n",
      "Epoch 10/20\n",
      "481/481 [==============================] - 1s 3ms/step - loss: 0.2722 - acc: 0.9111 - val_loss: 0.5160 - val_acc: 0.9808\n",
      "Epoch 11/20\n",
      "481/481 [==============================] - 1s 3ms/step - loss: 0.3095 - acc: 0.8654 - val_loss: 0.5381 - val_acc: 0.9615\n",
      "Epoch 12/20\n",
      "481/481 [==============================] - 1s 3ms/step - loss: 0.2653 - acc: 0.9060 - val_loss: 0.5337 - val_acc: 0.9808\n",
      "Epoch 13/20\n",
      "481/481 [==============================] - 1s 3ms/step - loss: 0.3168 - acc: 0.8968 - val_loss: 0.6384 - val_acc: 0.9551\n",
      "Epoch 14/20\n",
      "481/481 [==============================] - 1s 2ms/step - loss: 0.3151 - acc: 0.9249 - val_loss: 0.4248 - val_acc: 0.9679\n",
      "Epoch 15/20\n",
      "481/481 [==============================] - 1s 3ms/step - loss: 0.2970 - acc: 0.9020 - val_loss: 0.3895 - val_acc: 0.9872\n",
      "Epoch 16/20\n",
      "481/481 [==============================] - 2s 4ms/step - loss: 0.2916 - acc: 0.8834 - val_loss: 0.5601 - val_acc: 0.8654\n",
      "Epoch 17/20\n",
      "481/481 [==============================] - 1s 3ms/step - loss: 0.2523 - acc: 0.9305 - val_loss: 0.2094 - val_acc: 0.9936\n",
      "Epoch 18/20\n",
      "481/481 [==============================] - 1s 2ms/step - loss: 0.3017 - acc: 0.8463 - val_loss: 0.5696 - val_acc: 0.9744\n",
      "Epoch 19/20\n",
      "481/481 [==============================] - 1s 3ms/step - loss: 0.2611 - acc: 0.9056 - val_loss: 0.5672 - val_acc: 0.9808\n",
      "Epoch 20/20\n",
      "481/481 [==============================] - 1s 3ms/step - loss: 0.2843 - acc: 0.8869 - val_loss: 0.5633 - val_acc: 0.9744\n"
     ]
    }
   ],
   "source": [
    "history = base_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32, \n",
    "    validation_split=0.01,\n",
    "    shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 0s 763us/step - loss: 0.7578 - acc: 0.3100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7578141689300537, 0.3100312054157257]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.evaluate(X_test, y_test) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data with Feature Engineering on Raw X, Y, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tac</th>\n",
       "      <th>x_mean</th>\n",
       "      <th>y_mean</th>\n",
       "      <th>z_mean</th>\n",
       "      <th>x_std</th>\n",
       "      <th>y_std</th>\n",
       "      <th>z_std</th>\n",
       "      <th>x_aad</th>\n",
       "      <th>y_aad</th>\n",
       "      <th>z_aad</th>\n",
       "      <th>...</th>\n",
       "      <th>z_arg_diff</th>\n",
       "      <th>x_argmax_fft</th>\n",
       "      <th>y_argmax_fft</th>\n",
       "      <th>z_argmax_fft</th>\n",
       "      <th>x_argmin_fft</th>\n",
       "      <th>y_argmin_fft</th>\n",
       "      <th>z_argmin_fft</th>\n",
       "      <th>x_arg_diff_fft</th>\n",
       "      <th>y_arg_diff_fft</th>\n",
       "      <th>z_arg_diff_fft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.000585</td>\n",
       "      <td>-0.000364</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>0.008746</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.005187</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>-0.005559</td>\n",
       "      <td>-0.010026</td>\n",
       "      <td>0.043935</td>\n",
       "      <td>0.042405</td>\n",
       "      <td>0.042510</td>\n",
       "      <td>0.020880</td>\n",
       "      <td>0.019815</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>42</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>39</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.023324</td>\n",
       "      <td>0.015599</td>\n",
       "      <td>-0.027149</td>\n",
       "      <td>0.128959</td>\n",
       "      <td>0.106513</td>\n",
       "      <td>0.131192</td>\n",
       "      <td>0.088268</td>\n",
       "      <td>0.074175</td>\n",
       "      <td>0.094685</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>36</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.012703</td>\n",
       "      <td>-0.011832</td>\n",
       "      <td>-0.009105</td>\n",
       "      <td>0.029305</td>\n",
       "      <td>0.043782</td>\n",
       "      <td>0.033665</td>\n",
       "      <td>0.020353</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>0.023722</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.031388</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>-0.045044</td>\n",
       "      <td>0.120015</td>\n",
       "      <td>0.076248</td>\n",
       "      <td>0.114803</td>\n",
       "      <td>0.078569</td>\n",
       "      <td>0.052472</td>\n",
       "      <td>0.080129</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tac    x_mean    y_mean    z_mean     x_std     y_std     z_std     x_aad   \n",
       "0    0 -0.000585 -0.000364  0.004651  0.003299  0.004179  0.008746  0.002534  \\\n",
       "1    0  0.000710 -0.005559 -0.010026  0.043935  0.042405  0.042510  0.020880   \n",
       "2    1  0.023324  0.015599 -0.027149  0.128959  0.106513  0.131192  0.088268   \n",
       "3    0  0.012703 -0.011832 -0.009105  0.029305  0.043782  0.033665  0.020353   \n",
       "4    0 -0.031388  0.001648 -0.045044  0.120015  0.076248  0.114803  0.078569   \n",
       "\n",
       "      y_aad     z_aad  ...  z_arg_diff  x_argmax_fft  y_argmax_fft   \n",
       "0  0.002625  0.005187  ...          43            41            19  \\\n",
       "1  0.019815  0.026667  ...          17             1             3   \n",
       "2  0.074175  0.094685  ...          10             3            11   \n",
       "3  0.019700  0.023722  ...           8             0            45   \n",
       "4  0.052472  0.080129  ...           5            40             0   \n",
       "\n",
       "   z_argmax_fft  x_argmin_fft  y_argmin_fft  z_argmin_fft  x_arg_diff_fft   \n",
       "0            28            16            24            27              25  \\\n",
       "1             1            17            42            28              16   \n",
       "2             6            24            16            36              21   \n",
       "3             6            34            24            21              34   \n",
       "4            10            24            42             9              16   \n",
       "\n",
       "   y_arg_diff_fft  z_arg_diff_fft  \n",
       "0               5               1  \n",
       "1              39              27  \n",
       "2               5              30  \n",
       "3              21              15  \n",
       "4              42               1  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## PID = DC6359\n",
    "df = pd.read_csv(\"../data/DC6359_feature_engg_updated_new.csv\")\n",
    "df = df.sample(frac=1, random_state=1).reset_index()\n",
    "df = df.drop(['Unnamed: 0', 'index'], axis=1) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tac</th>\n",
       "      <th>x_mean</th>\n",
       "      <th>y_mean</th>\n",
       "      <th>z_mean</th>\n",
       "      <th>x_std</th>\n",
       "      <th>y_std</th>\n",
       "      <th>z_std</th>\n",
       "      <th>x_aad</th>\n",
       "      <th>y_aad</th>\n",
       "      <th>z_aad</th>\n",
       "      <th>...</th>\n",
       "      <th>z_arg_diff</th>\n",
       "      <th>x_argmax_fft</th>\n",
       "      <th>y_argmax_fft</th>\n",
       "      <th>z_argmax_fft</th>\n",
       "      <th>x_argmin_fft</th>\n",
       "      <th>y_argmin_fft</th>\n",
       "      <th>z_argmin_fft</th>\n",
       "      <th>x_arg_diff_fft</th>\n",
       "      <th>y_arg_diff_fft</th>\n",
       "      <th>z_arg_diff_fft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.016726</td>\n",
       "      <td>0.003708</td>\n",
       "      <td>0.004323</td>\n",
       "      <td>0.004929</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>0.003611</td>\n",
       "      <td>0.003963</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.010015</td>\n",
       "      <td>0.016626</td>\n",
       "      <td>0.013341</td>\n",
       "      <td>0.010943</td>\n",
       "      <td>0.010745</td>\n",
       "      <td>0.006699</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>47</td>\n",
       "      <td>46</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>0.009744</td>\n",
       "      <td>0.013846</td>\n",
       "      <td>0.017084</td>\n",
       "      <td>0.013323</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>0.010165</td>\n",
       "      <td>0.008480</td>\n",
       "      <td>0.009637</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.010908</td>\n",
       "      <td>0.011838</td>\n",
       "      <td>0.009810</td>\n",
       "      <td>0.012986</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.007362</td>\n",
       "      <td>0.009902</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>28</td>\n",
       "      <td>44</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.009971</td>\n",
       "      <td>0.010272</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.007611</td>\n",
       "      <td>0.010529</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0.005775</td>\n",
       "      <td>0.007740</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tac    x_mean    y_mean    z_mean     x_std     y_std     z_std     x_aad   \n",
       "0    0  0.004578  0.007246  0.016726  0.003708  0.004323  0.004929  0.003109  \\\n",
       "1    0  0.001759  0.010015  0.016626  0.013341  0.010943  0.010745  0.006699   \n",
       "2    0  0.002363  0.009744  0.013846  0.017084  0.013323  0.014038  0.010165   \n",
       "3    0  0.002435  0.008929  0.010908  0.011838  0.009810  0.012986  0.007481   \n",
       "4    0  0.000526  0.009971  0.010272  0.005405  0.007611  0.010529  0.003908   \n",
       "\n",
       "      y_aad     z_aad  ...  z_arg_diff  x_argmax_fft  y_argmax_fft   \n",
       "0  0.003611  0.003963  ...          22            20            23  \\\n",
       "1  0.006029  0.005773  ...           2             6            47   \n",
       "2  0.008480  0.009637  ...          11             6             1   \n",
       "3  0.007362  0.009902  ...          83             0             8   \n",
       "4  0.005775  0.007740  ...           5            32            16   \n",
       "\n",
       "   z_argmax_fft  x_argmin_fft  y_argmin_fft  z_argmin_fft  x_arg_diff_fft   \n",
       "0            21            24            26            31               4  \\\n",
       "1            46            21            12            14              15   \n",
       "2             4            18            24            37              12   \n",
       "3            38            34            28            44              34   \n",
       "4             1            35            20            26               3   \n",
       "\n",
       "   y_arg_diff_fft  z_arg_diff_fft  \n",
       "0               3              10  \n",
       "1              35              32  \n",
       "2              23              33  \n",
       "3              20               6  \n",
       "4               4              25  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## PID = BU4707\n",
    "test_df = pd.read_csv(\"../data/BU4707_feature_engg_updated_new.csv\")\n",
    "test_df = test_df.drop(['Unnamed: 0'], axis=1) \n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6216, 107), (4490, 107))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6216, 107), (6216, 41), (4490, 107), (4490, 41))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = df.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find features with correlation greater than 0.95 \n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.80)]\n",
    "to_drop\n",
    "\n",
    "# Drop features \n",
    "new_df = df.drop(to_drop, axis=1)\n",
    "new_test_df = test_df.drop(to_drop, axis=1)\n",
    "df.shape, new_df.shape, test_df.shape, new_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6216, 40), (6216,), (4490, 40), (4490,))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = new_df.drop(['tac'], axis=1)\n",
    "y_train = new_df.tac\n",
    "X_test = new_test_df.drop(['tac'], axis=1)\n",
    "y_test = new_test_df.tac \n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6216, 1), (4490, 1))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.reshape(y_train, (-1,1))\n",
    "y_test = np.reshape(y_test, (-1,1))\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_68 (Dense)            (83965, 20, 128)          512       \n",
      "                                                                 \n",
      " dense_69 (Dense)            (83965, 20, 64)           8256      \n",
      "                                                                 \n",
      " dense_70 (Dense)            (83965, 20, 32)           2080      \n",
      "                                                                 \n",
      " dense_71 (Dense)            (83965, 20, 1)            33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,881\n",
      "Trainable params: 10,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "fc_layer1 = keras.layers.Dense(units=128, activation = 'relu')\n",
    "fc_layer2 = keras.layers.Dense(units=64, activation = 'relu')\n",
    "fc_layer3 = keras.layers.Dense(units=32, activation = 'relu')\n",
    "fc_layer4 = keras.layers.Dense(units=1, activation = 'sigmoid')\n",
    "# Cant use softmax at the end since it will normalize and give 1 \n",
    "base_model = keras.Sequential([\n",
    "fc_layer1,\n",
    "fc_layer2,\n",
    "fc_layer3,\n",
    "fc_layer4\n",
    "])\n",
    "\n",
    "base_model.compile(loss=keras.losses.BinaryCrossentropy(from_logits = False), \n",
    "                   optimizer=keras.optimizers.Adam(0.001, beta_1=0.9, beta_2= 0.999), \n",
    "                   metrics=['acc']) \n",
    "\n",
    "base_model.build((X_train.shape))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.Sequential()\n",
    "# model.add(keras.layers.LSTM(20, input_shape=[40,]))\n",
    "# model.add(keras.layers.TimeDistributed(keras.layers.Dense(1, activation='sigmoid')))\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.build((X_train.shape)) \n",
    "# model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 1s 6ms/step - loss: 0.7457 - acc: 0.7827 - val_loss: 0.7122 - val_acc: 0.7937\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4901 - acc: 0.8264 - val_loss: 0.5352 - val_acc: 0.7778\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4237 - acc: 0.8407 - val_loss: 0.5123 - val_acc: 0.8254\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4079 - acc: 0.8445 - val_loss: 0.4963 - val_acc: 0.8413\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3920 - acc: 0.8505 - val_loss: 0.5000 - val_acc: 0.8254\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3775 - acc: 0.8544 - val_loss: 0.4841 - val_acc: 0.8254\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3666 - acc: 0.8555 - val_loss: 0.4850 - val_acc: 0.8254\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3591 - acc: 0.8563 - val_loss: 0.4790 - val_acc: 0.8254\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3503 - acc: 0.8584 - val_loss: 0.4834 - val_acc: 0.8413\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3447 - acc: 0.8597 - val_loss: 0.4884 - val_acc: 0.8413\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3380 - acc: 0.8633 - val_loss: 0.4864 - val_acc: 0.8413\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3323 - acc: 0.8635 - val_loss: 0.4753 - val_acc: 0.8413\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3269 - acc: 0.8656 - val_loss: 0.4986 - val_acc: 0.8254\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3233 - acc: 0.8682 - val_loss: 0.4780 - val_acc: 0.8254\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3149 - acc: 0.8701 - val_loss: 0.4894 - val_acc: 0.8413\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3085 - acc: 0.8714 - val_loss: 0.4636 - val_acc: 0.8254\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3022 - acc: 0.8745 - val_loss: 0.4789 - val_acc: 0.8254\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2974 - acc: 0.8778 - val_loss: 0.4727 - val_acc: 0.8413\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2931 - acc: 0.8783 - val_loss: 0.5158 - val_acc: 0.8413\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2859 - acc: 0.8812 - val_loss: 0.5259 - val_acc: 0.8413\n"
     ]
    }
   ],
   "source": [
    "history = base_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=256, \n",
    "    validation_split=0.01, \n",
    "    shuffle=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 527us/step - loss: 0.7980 - acc: 0.6793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7980446815490723, 0.679287314414978]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sliding window dataset - Model does not learn on this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/pickles/data_slidingwindowTrue10_samplingrate20_df_DC6359.p\", 'rb') as f:\n",
    "  data = pk.load(f)\n",
    "X = data['X']\n",
    "Y = data['Y']\n",
    "# dataframe = data['data']\n",
    "# dataframe['pid'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_5 (LSTM)               (None, 256)               266240    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 299,265\n",
      "Trainable params: 299,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(\n",
    "      keras.layers.LSTM(\n",
    "          units=256,\n",
    "          input_shape=[X.shape[1], X.shape[2]]\n",
    "      )\n",
    ")\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "model.add(keras.layers.Dense(y_train.shape[1], activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  optimizer='adam', \n",
    "  metrics=['acc'] \n",
    ")\n",
    "\n",
    "model.build((X.shape))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "61/61 [==============================] - 38s 598ms/step - loss: 0.4650 - acc: 0.8436 - val_loss: 0.4176 - val_acc: 0.8526\n",
      "Epoch 2/20\n",
      "61/61 [==============================] - 38s 625ms/step - loss: 0.4206 - acc: 0.8521 - val_loss: 0.4179 - val_acc: 0.8526\n",
      "Epoch 3/20\n",
      "61/61 [==============================] - 37s 604ms/step - loss: 0.4185 - acc: 0.8521 - val_loss: 0.4199 - val_acc: 0.8526\n",
      "Epoch 4/20\n",
      "61/61 [==============================] - 37s 607ms/step - loss: 0.4181 - acc: 0.8521 - val_loss: 0.4175 - val_acc: 0.8526\n",
      "Epoch 5/20\n",
      "61/61 [==============================] - 47s 765ms/step - loss: 0.4183 - acc: 0.8521 - val_loss: 0.4181 - val_acc: 0.8526\n",
      "Epoch 6/20\n",
      "61/61 [==============================] - 37s 612ms/step - loss: 0.4196 - acc: 0.8520 - val_loss: 0.4188 - val_acc: 0.8526\n",
      "Epoch 7/20\n",
      "61/61 [==============================] - 37s 610ms/step - loss: 0.4202 - acc: 0.8521 - val_loss: 0.4188 - val_acc: 0.8526\n",
      "Epoch 8/20\n",
      "61/61 [==============================] - 38s 624ms/step - loss: 0.4174 - acc: 0.8521 - val_loss: 0.4172 - val_acc: 0.8526\n",
      "Epoch 9/20\n",
      "61/61 [==============================] - 38s 626ms/step - loss: 0.4301 - acc: 0.8521 - val_loss: 0.4181 - val_acc: 0.8526\n",
      "Epoch 10/20\n",
      "61/61 [==============================] - 39s 638ms/step - loss: 0.4202 - acc: 0.8521 - val_loss: 0.4182 - val_acc: 0.8526\n",
      "Epoch 11/20\n",
      "61/61 [==============================] - 40s 658ms/step - loss: 0.4205 - acc: 0.8521 - val_loss: 0.4180 - val_acc: 0.8526\n",
      "Epoch 12/20\n",
      "61/61 [==============================] - 38s 618ms/step - loss: 0.4193 - acc: 0.8521 - val_loss: 0.4187 - val_acc: 0.8526\n",
      "Epoch 13/20\n",
      "61/61 [==============================] - 39s 644ms/step - loss: 0.4176 - acc: 0.8521 - val_loss: 0.4186 - val_acc: 0.8526\n",
      "Epoch 14/20\n",
      "61/61 [==============================] - 38s 627ms/step - loss: 0.4172 - acc: 0.8521 - val_loss: 0.4188 - val_acc: 0.8526\n",
      "Epoch 15/20\n",
      "61/61 [==============================] - 37s 605ms/step - loss: 0.4175 - acc: 0.8521 - val_loss: 0.4181 - val_acc: 0.8526\n",
      "Epoch 16/20\n",
      "61/61 [==============================] - 37s 601ms/step - loss: 0.4169 - acc: 0.8521 - val_loss: 0.4186 - val_acc: 0.8526\n",
      "Epoch 17/20\n",
      "61/61 [==============================] - 37s 608ms/step - loss: 0.4185 - acc: 0.8521 - val_loss: 0.4187 - val_acc: 0.8526\n",
      "Epoch 18/20\n",
      "61/61 [==============================] - 38s 625ms/step - loss: 0.4175 - acc: 0.8521 - val_loss: 0.4181 - val_acc: 0.8526\n",
      "Epoch 19/20\n",
      "61/61 [==============================] - 38s 630ms/step - loss: 0.4174 - acc: 0.8521 - val_loss: 0.4184 - val_acc: 0.8526\n",
      "Epoch 20/20\n",
      "61/61 [==============================] - 39s 635ms/step - loss: 0.4170 - acc: 0.8521 - val_loss: 0.4188 - val_acc: 0.8526\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X, Y,\n",
    "    epochs=20,\n",
    "    batch_size=256, \n",
    "    validation_split=0.01, \n",
    "    shuffle=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_2 (Bidirectio  (15543, 512)             532480    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (15543, 512)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (15543, 128)              65664     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (15543, 1)                129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 598,273\n",
      "Trainable params: 598,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Bidirectional(keras.layers.LSTM(units=256,input_shape=[X_train.shape[1], X_train.shape[2]])))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "model.add(keras.layers.Dense(y_train.shape[1], activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer=keras.optimizers.Adam(0.001),metrics=['acc']) \n",
    "model.build((X.shape)) \n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "61/61 [==============================] - 48s 746ms/step - loss: 0.4486 - acc: 0.8491 - val_loss: 0.4189 - val_acc: 0.8526\n",
      "Epoch 2/20\n",
      "61/61 [==============================] - 46s 747ms/step - loss: 0.4176 - acc: 0.8521 - val_loss: 0.4157 - val_acc: 0.8526\n",
      "Epoch 3/20\n",
      "61/61 [==============================] - 46s 752ms/step - loss: 0.4174 - acc: 0.8521 - val_loss: 0.4111 - val_acc: 0.8526\n",
      "Epoch 4/20\n",
      "20/61 [========>.....................] - ETA: 35s - loss: 0.4428 - acc: 0.8521"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X, Y,\n",
    "    epochs=20,\n",
    "    batch_size=256, \n",
    "    validation_split=0.01, \n",
    "    shuffle=False)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
